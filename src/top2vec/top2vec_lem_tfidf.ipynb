{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NST Preprocessing Experiment (NPE):\n",
    "## Top2Vec model from lem+TFIDF dataset\n",
    "\n",
    "Generating a Topic-to-vector (Top2Vec) model from the lemmatized + TF-IDF-cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from top2vec import Top2Vec\n",
    "\n",
    "from src.utils.file_management import (\n",
    "    ROOT_PATH,\n",
    "    load_subtitles,\n",
    "    write_topics_file)\n",
    "\n",
    "from src.utils.tables_and_plots import (\n",
    "    display_n_wordclouds,\n",
    "    create_wordcloud\n",
    ")\n",
    "\n",
    "NST_SAMPLE_SIZE = 1000\n",
    "EMBEDDING_MODEL = \"distiluse\"\n",
    "PIPELINE = \"lem_tfidf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed CSV file\n",
    "folder_path_data = r\"nst_preprocessing_experiment/preprocessed_data\"\n",
    "file_name_data = f\"npe_{NST_SAMPLE_SIZE}_{PIPELINE}\"\n",
    "\n",
    "subtitled_programs = load_subtitles(folder_path_data, file_name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hjertelig', 'velkommen', 'sommeråpent', 'vikingtid', 'kåre']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_program_id = random.choice(list(subtitled_programs.keys()))\n",
    "example_program_slice = 5\n",
    "subtitled_programs[example_program_id][:example_program_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating tokens to long strings/documents\n",
    "for (program_id, subtitles) in subtitled_programs.items():\n",
    "    subtitled_programs[program_id] = \" \".join(subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating/loading model from dataset\n",
    "\n",
    "folder_path_model = r\"nst_preprocessing_experiment/models/top2vec\"\n",
    "file_name_model = f\"npe_{NST_SAMPLE_SIZE}_{PIPELINE}_top2vec_{EMBEDDING_MODEL}\"\n",
    "file_path = os.path.join(ROOT_PATH, folder_path_model, PIPELINE, file_name_model)\n",
    "\n",
    "top2vec = None\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    top2vec = Top2Vec.load(file_path)\n",
    "else:\n",
    "    if EMBEDDING_MODEL == \"distiluse\":\n",
    "        embedding = \"distiluse-base-multilingual-cased\"\n",
    "    top2vec = Top2Vec(documents=list(subtitled_programs.values()), embedding_model=embedding, min_count=5, speed=\"fast-learn\", workers=mp.cpu_count() - 2)\n",
    "    top2vec.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = top2vec.get_num_topics()\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([328, 326, 162,  62,  43,  40,  38], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes, _ = top2vec.get_topic_sizes()\n",
    "topic_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_nums = top2vec.get_topics(num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_scores = [dict(zip(topic_words[i][:10], word_scores[i])) for i in topic_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "{'oooooh': 0.2431274, 'hahaha': 0.22307909, 'haha': 0.22011882, 'hahahe': 0.2180962, 'ooh': 0.21294086, 'ooo': 0.21280807, 'oh': 0.2107629, 'uff': 0.20840901, 'mmm': 0.20784535, 'aha': 0.20371282}\n",
      "\n",
      " 1\n",
      "{'skattepolitikk': 0.15280613, 'fuck': 0.14839816, 'fylkespolitiker': 0.1478839, 'politireforme': 0.14088814, 'oooooh': 0.14087343, 'storpolitikk': 0.13537058, 'politikk': 0.13256164, 'politisk': 0.13180478, 'uff': 0.13116929, 'hahaha': 0.12797157}\n",
      "\n",
      " 2\n",
      "{'flekkefjord': 0.17402978, 'hjeltefjorden': 0.17355998, 'oooooh': 0.17256936, 'nordfjord': 0.16683225, 'takke': 0.16014099, 'snø': 0.15832841, 'fjellvegg': 0.15705876, 'oslofjorden': 0.15450689, 'ooo': 0.15227655, 'takknemlig': 0.15129536}\n",
      "\n",
      " 3\n",
      "{'fotballag': 0.19771329, 'gullmedalje': 0.19519584, 'fotballkamp': 0.1941242, 'fotball': 0.18953875, 'fotballe': 0.1883981, 'fotballvm': 0.17854145, 'verdenscup': 0.17768171, 'sølvmedalje': 0.17474395, 'fotballbane': 0.17177646, 'bronsemedalje': 0.17167394}\n",
      "\n",
      " 4\n",
      "{'russernes': 0.32719892, 'russisk': 0.3231959, 'russlands': 0.28626403, 'rusavhengig': 0.28178784, 'russland': 0.27605414, 'russetid': 0.27102232, 'sovjetisk': 0.26278487, 'russ': 0.25480157, 'ukrainas': 0.24137206, 'russer': 0.24044573}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"\\n\", i)\n",
    "    print(topic_word_scores[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "display_n_wordclouds() got an unexpected keyword argument 'width'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15760/3098482486.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_n_wordclouds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_word_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Top2Vec: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPIPELINE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: display_n_wordclouds() got an unexpected keyword argument 'width'"
     ]
    }
   ],
   "source": [
    "display_n_wordclouds(topic_word_scores, \"Top2Vec: \" + PIPELINE, num_topics, dpi=200, width=1600, height=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_word_cloud = f\"nst_preprocessing_experiment/results/word_clouds/top2vec/{PIPELINE}\"\n",
    "\n",
    "for i in range(num_topics):\n",
    "    topic_wordcloud = create_wordcloud(topic_word_scores[i], width=1600, height=1600)\n",
    "    topic_wordcloud.to_file(os.path.join(ROOT_PATH, folder_path_word_cloud, str(file_name_model + f\"_{i}.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save topic words of model to file\n",
    "\n",
    "topic_words_numbered = [(i, list(topic_words[i])) for i in range(num_topics)]\n",
    "\n",
    "folder_path_topics = r\"nst_preprocessing_experiment/results/topics/\"\n",
    "file_name_topics = file_name_data\n",
    "\n",
    "write_topics_file(folder_path_topics, file_name_topics, topic_words_numbered, model=\"top2vec\", top2vec_embedding=EMBEDDING_MODEL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "319280241ff3efc49142e6dc9500d3472c32e7319f7a25b1b817d430a24847ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
